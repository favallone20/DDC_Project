{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_4QVwi6jJga"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from scipy import interpolate\n",
        "from scipy.interpolate import interpolate\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoL_nLQGjJgc"
      },
      "source": [
        "$\\textbf{Plant}$\n",
        "\n",
        "This class which provides an interface to manage the binning of a trajectory of states and control inputs to obtain the conditional pmf $f(x_k|x_{k-1}, u_k)$ of the plant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0y9L3gEjJgg"
      },
      "outputs": [],
      "source": [
        "class Plant:\n",
        "\n",
        "    def __init__(self, x_max, x_min, u_max, u_min, x_discr, u_discr):\n",
        "        # Bounds for u and x\n",
        "        self.x_max = x_max\n",
        "        self.x_min = x_min\n",
        "        self.u_max = u_max\n",
        "        self.u_min = u_min\n",
        "\n",
        "        # Amount of bins (resolution) for u and x\n",
        "        self.x_discr = x_discr\n",
        "        self.u_discr = u_discr\n",
        "\n",
        "        # Discretization step for x and u\n",
        "        self.x_step = (self.x_max - self.x_min)/self.x_discr\n",
        "        self.u_step = (self.u_max - self.u_min)/self.u_discr\n",
        "    \n",
        "        self.x_axis = [self.x_min + (i+0.5)*self.x_step for i in range(self.x_discr)]\n",
        "        self.u_axis = [self.u_min + (j+0.5)*self.u_step for j in range(self.u_discr)]  \n",
        "\n",
        "        self.full_joint = np.zeros((self.x_discr, self.u_discr, self.x_discr)) #Initializing f(x_k, u_k, x_{k-1}) (3D array)\n",
        "        self.reduced_joint = np.zeros((self.x_discr, self.u_discr)) #Initializing f(u_k, x_{k-1}) (2D array)\n",
        "        self.f_x = np.zeros((self.x_discr, self.u_discr, self.x_discr)) #Initializing f(x_k| u_k, x_{k-1}) (3D array)\n",
        "\n",
        "    def getXdiscr(self):\n",
        "        return self.x_discr\n",
        "\n",
        "    def getUdiscr(self):\n",
        "        return self.u_discr\n",
        "\n",
        "    def getXmin(self):\n",
        "        return self.x_min\n",
        "\n",
        "    def getUmin(self):\n",
        "        return self.u_min\n",
        "\n",
        "    def getXmax(self):\n",
        "        return self.x_max\n",
        "\n",
        "    def getUmax(self):\n",
        "        return self.u_max\n",
        "\n",
        "    def getXstep(self):\n",
        "        return self.x_step\n",
        "\n",
        "    def getUstep(self):\n",
        "        return self.u_step\n",
        "\n",
        "    def getXaxis(self):\n",
        "        return self.x_axis\n",
        "\n",
        "    def getUaxis(self):\n",
        "        return self.u_axis\n",
        "\n",
        "    def getPlant(self, x, u):\n",
        "        # Function that handles the binning of a trajectory\n",
        "        # Given a history for the state and the input (ie two lists), browses each list and increments the appropriate histogram bins \n",
        "        for i in range(len(x)-1): #N-1 iterations (since we study consecutive pairs of states, one iteration less than the number of states)\n",
        "            xkm1 = x[i] #x_{k-1}\n",
        "            xk = x[i+1] #x_k\n",
        "            uk = u[i+1] #u_k\n",
        "\n",
        "            #Calculating the index from the min value and the discretization step\n",
        "            indXkm1 = int((xkm1 - self.x_min)//self.x_step)\n",
        "            indXk = int((xk - self.x_min)//self.x_step)\n",
        "            indUk = int((uk - self.u_min)//self.u_step)\n",
        "            self.full_joint[indXkm1][indUk][indXk] += 1 #Updating the full joint 'pmf'\n",
        "            self.reduced_joint[indXkm1][indUk] += 1 #Updating the partial 'pmf'\n",
        "\n",
        "        for i in range(self.x_discr): #For each x_{k-1}\n",
        "            for j in range(self.u_discr): #For each u_k\n",
        "                for k in range(self.x_discr): #For each x_k\n",
        "                    if self.full_joint[i][j][k] == 0: #Failsafe to avoid dividing by zero\n",
        "                        self.f_x[i][j][k] = 0 #If we've never encountered this state, let the conditionnal value be zero\n",
        "                    else:\n",
        "                        self.f_x[i][j][k] = self.full_joint[i][j][k]/self.reduced_joint[i][j] #Divide the full joint by the partial joint\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHvhUcfEjJgj"
      },
      "source": [
        "$\\textbf{GaussianPlant}$\n",
        "\n",
        "This class extends the class Plant and provides an interface to get the conditional pmf of the plant, using the explicit formula of the Gaussian.\n",
        "\n",
        "The $\\textit{GaussianPlant}$ class has been used to obtain a Gaussian conditional pmf $f(x_k|x_{k-1}, u_k)$ of the plant, in the form of an entry of $[mean, std]$, usable in an algorithm of control from demonstration that employes analytical computational techniques, implemented in the $\\textit{AnalyticalSolver}$ class, or in the form of a normal Gaussian distribution that can be used in a control from demonstration algorithm that uses numerical computational techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lp969Pk7jJgk"
      },
      "outputs": [],
      "source": [
        "class GaussianPlant(Plant):\n",
        "\n",
        "    def __init__(self, x_max, x_min, u_max, u_min, x_discr, u_discr, a, b, sigma, mode=\"analytic\"):\n",
        "        super().__init__(x_max, x_min, u_max, u_min, x_discr, u_discr)\n",
        "        self.sigma = sigma\n",
        "        self.a = a\n",
        "        self.b = b\n",
        "        self.mode = mode\n",
        "        \n",
        "\n",
        "    def getPlant(self, x = None, y = None):\n",
        "        # Function for getting the plant (f_x or g_x) from the parameters.\n",
        "        # The arguments are the linear parameters for the mean and the std.\n",
        "        # The Gaussians are simply coded as [mean, std] to simplify calculations\n",
        "        if self.mode == \"analytic\":\n",
        "            self.f_x = np.zeros((self.x_discr, self.u_discr, 2)) # Initializing the empty array\n",
        "        for i in range(self.x_discr): # Iterating over the state space for x_{k-1}\n",
        "            x_km1 = self.x_min + (i+0.5)*self.x_step # Calculating x_{k-1}\n",
        "            for j in range(self.u_discr): # Iterating over the action space for u_k\n",
        "                u_k = self.u_min + (j+0.5)*self.u_step # Calculating u_k\n",
        "                mu = self.a*x_km1 + self.b*u_k # Calculating the average of the Gaussian\n",
        "                if self.mode == \"analytic\":\n",
        "                    self.f_x[i][j] = [mu, self.sigma] # Adding the Gaussian in [mean, std] form to the array\n",
        "                else:\n",
        "                    self.f_x[i][j] = self.sample_gaussian(mu, self.sigma, self.x_axis)\n",
        "        return(self.f_x)\n",
        "\n",
        "    def sample_gaussian(self, mu, sigma, Ax):\n",
        "        # Where Ax is the horizontal axis\n",
        "        pmf = [0]*len(Ax) # Initializing the pmf\n",
        "        for i in range(len(Ax)): # Iterating over the state space to calculate the elements of the pmf\n",
        "            pmf[i] = np.exp(-0.5*((Ax[i]-mu)/sigma)**2)  # Using the explicit formula for the Gaussian\n",
        "                                                         # The multiplicative factor is omitted as the pmf will be normalized\n",
        "        S = np.sum(pmf) # Calculating the sum for normalization\n",
        "        return([x/S for x in pmf])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibq8DZaPjJgl"
      },
      "source": [
        "$\\textbf{NumericalSolver}$\n",
        "\n",
        "This class provides an interface for carrying out control from demonstration using numerical computational techniques and it is capable of receiving any type of probability distribution as input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0lPXjICjJgl"
      },
      "outputs": [],
      "source": [
        "class NumericalSolver:\n",
        "\n",
        "    def __init__(self, f, g, g_u):\n",
        "        self.f = f # Plant object of the agent\n",
        "        self.g = g # Plant object of the demonstrator\n",
        "        self.g_u = g_u # TargetPolicy object\n",
        "\n",
        "\n",
        "    def DKL(self, f, g):\n",
        "        # Kullback-Leibler divergence between two arrays, they have to be pmfs (ie histograms that sum to 1)\n",
        "        return(np.sum([f[i]*math.log(f[i]/g[i]) for i in range(len(f)) if f[i]!=0 and g[i]!= 0]))\n",
        "\n",
        "    def runFPD(self, xStart, tHor=0):\n",
        "\n",
        "        x_discr = self.f.getXdiscr()\n",
        "        u_discr = self.f.getUdiscr()\n",
        "\n",
        "        f_x = self.f.getPlant()\n",
        "        g_x = self.g.getPlant()\n",
        "\n",
        "        # Runs the control from demos algorithm, assuming the agent is at state xStart (given as an index!) with a time horizon tHor\n",
        "        # Initializing zero gamma function\n",
        "        gamma = np.zeros(x_discr)\n",
        "        # If time horizon is greater than 0 we consider the states from the min between (xStart + time horizon -1) and \n",
        "        # (d_discr-1) (in order to not exceed the dimension of the array) to (xStart + 1)\n",
        "        if tHor > 0: \n",
        "            stateAtTime = list(range(min(xStart + tHor-1, x_discr - 2), xStart + 1, -1))\n",
        "        # Else we don't take into account the future states, but we consider only the next time step\n",
        "        else: \n",
        "            stateAtTime = [] \n",
        "        \n",
        "        # We calculate gamma from xStart + time horizon to xStart + 1\n",
        "        for xk, uk in zip(stateAtTime, stateAtTime):\n",
        "            # We initialize an auxiliary array, which we will use to calculate gamma_k(x_k)\n",
        "            gammaArray = np.zeros(u_discr)\n",
        "            # We get f(x_{k+1}|x_k,u_{k+1})\n",
        "            plant = f_x[xk][uk+1] \n",
        "            # We get g(x_{k+1}|x_k,u_{k+1})\n",
        "            target_plant = g_x[xk][uk+1]\n",
        "            # We build the array with the exp of the numeric DKL of the 'future' plants\n",
        "            gammaArray[uk+1] = np.exp(-self.DKL(plant, target_plant))\n",
        "            # Finally we calculate gamma, which is the log of the expectation of our auxiliary array\n",
        "            gamma[xk] = np.log(np.dot(self.g_u.target_policy(xk),gammaArray)) \n",
        "        \n",
        "        # Previous state x_(k-1)\n",
        "        xkm1 = xStart  \n",
        "        policy = np.zeros(u_discr)\n",
        "        # We extract the corresponding target policy, g(u_k|x_{k-1}) \n",
        "        target_pol = self.g_u.target_policy(xkm1) \n",
        "        for u in range(u_discr): \n",
        "            # We get f(x_{k}|x_{k - 1}, u_k)\n",
        "            plant = f_x[xkm1][u]\n",
        "            # We get g(x_{k}|x_{k - 1}, u_k)\n",
        "            target_plant = g_x[xkm1][u]\n",
        "            # We sample plant for expectations\n",
        "            policy[u] = target_pol[u]*np.exp(-self.DKL(plant, target_plant) + np.dot(plant,gamma))\n",
        "        # We calculate the integral\n",
        "        S = np.sum(policy)\n",
        "        # We return the normalized result\n",
        "        return([elt/S for elt in policy]) \n",
        "\n",
        "    def closedLoop(self, tHor=0):\n",
        "\n",
        "        position = []\n",
        "        speed = []\n",
        "        x = 0\n",
        "\n",
        "        x_discr = self.f.getXdiscr()\n",
        "        u_discr = self.f.getUdiscr()\n",
        "\n",
        "        x_step = self.f.getXstep()\n",
        "        u_step = self.f.getUstep()\n",
        "\n",
        "        u_min = self.f.getUmin()\n",
        "        x_min = self.f.getXmin()\n",
        "\n",
        "        f_x = self.f.getPlant()\n",
        "\n",
        "        while(x < x_discr-20):\n",
        "            policy = self.runFPD(x, tHor) # We get the optimal policy\n",
        "            u = np.random.choice(range(u_discr), p=policy) # We choose a random index u from the policy according to the distribution of the policy\n",
        "            plant = f_x[x][u] # We get the conditional pmf of x_k: f(x_k|x_{k-1}, u_k)\n",
        "            # We get the new state from the plant\n",
        "            x = np.random.choice(range(x_discr), p=plant)\n",
        "            x = max(x, 0)\n",
        "\n",
        "            # We compute the value of state from the state index\n",
        "            trueX = x_min + x_step*x\n",
        "\n",
        "            # We compute the value of input from the input index\n",
        "            trueU = u_min + u_step*u\n",
        "            \n",
        "            position.append(trueX)\n",
        "            speed.append(trueU)\n",
        "\n",
        "            print(\"Speed: \" + str(trueU) + \" km/h\")\n",
        "            print(\"New position: \" + str(trueX) + \" m\")\n",
        "    \n",
        "        plt.figure(figsize=(8, 6), dpi=80)\n",
        "        plt.subplot(2,1,1)\n",
        "        plt.title(\"Simulation of the closed loop\")\n",
        "        plt.ylabel(r'Position $(m)$', fontsize=12)\n",
        "        plt.plot(position)\n",
        "        \n",
        "        plt.subplot(2,1,2)\n",
        "        plt.xlabel(r'Time $(s)$', fontsize=12)\n",
        "        plt.ylabel(r'Velocity $(km/h)$', fontsize=12)\n",
        "        plt.plot(speed)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T_eqqcajJgm"
      },
      "source": [
        "$\\textbf{AnalyticalSolver}$\n",
        "\n",
        "This class provides an interface to perform the control from demonstration using analytic computing techniques, in particular using the explicit formula of the Gaussian.\n",
        "\n",
        "The pmf of the agent and of the demonstrator have to be Gaussian distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AmTJSTljJgm"
      },
      "outputs": [],
      "source": [
        "class AnalyticalSolver(NumericalSolver):\n",
        "\n",
        "    def __init__(self, f, g, g_u):\n",
        "        super().__init__(f, g, g_u)\n",
        "\n",
        "    def DKL(self, f, g):\n",
        "        mu1 = f[0] #Extracting means\n",
        "        mu2 = g[0]\n",
        "        sigma1 = f[1] #Extracting stds\n",
        "        sigma2 = g[1]\n",
        "        \n",
        "        el1 = math.log(sigma1/sigma2) # Calculating the sub-elements of the formula\n",
        "        el2 = sigma1*sigma1 + (mu1-mu2)*(mu1-mu2)\n",
        "        el3 = 2*sigma2*sigma2\n",
        "        \n",
        "        return(el1 + el2/el3 - 0.5)\n",
        "\n",
        "    def runFPD(self, xStart, tHor=0):\n",
        "\n",
        "        x_discr = self.f.getXdiscr()\n",
        "        u_discr = self.f.getUdiscr()\n",
        "\n",
        "        f_x = self.f.getPlant()\n",
        "        g_x = self.g.getPlant()\n",
        "\n",
        "        #Runs the control from demos algorithm, assuming the agent is at state xStart (given as an index!) with a time horizon tHor\n",
        "        #Initializing zero gamma function\n",
        "        gamma = np.zeros(x_discr)\n",
        "        # If time horizon is greater than 0 we consider the states from the min between (xStart + time horizon -1) and\n",
        "        # (d_discr-1) (in order to not exceed the dimension of the array) to (xStart + 1)\n",
        "        if tHor >0: \n",
        "            stateAtTime = list(range(min(xStart + tHor-1, x_discr - 2), xStart + 1, -1))\n",
        "        # Else we don't take into account the future states, but we consider only the next time step\n",
        "        else: \n",
        "            stateAtTime = [] \n",
        "        \n",
        "        # We calculate gamma from xStart + time horizon to xStart + 1\n",
        "        for xk, uk in zip(stateAtTime, stateAtTime):\n",
        "            # We initialize an auxiliary array, which we will use to calculate gamma_k(x_k)\n",
        "            gammaArray = np.zeros(u_discr)\n",
        "            # We get f(x_{k+1}|x_k,u_{k+1}) in [mean, std] form\n",
        "            plant = f_x[xk][uk+1]\n",
        "            # We get g(x_{k+1}|x_k,u_{k+1}) in [mean, std] form\n",
        "            target_plant = g_x[xk][uk+1]\n",
        "            # We build the array with the exp of the analytic DKL of the 'future' plants\n",
        "            gammaArray[uk+1] = np.exp(-self.DKL(plant, target_plant))\n",
        "            # Finally we calculate gamma, which is the log of the expectation of our auxiliary array\n",
        "            gamma[xk] = np.log(np.dot(self.g_u.target_policy(xk),gammaArray)) \n",
        "        \n",
        "        # Previous state x_(k-1)\n",
        "        xkm1 = xStart  \n",
        "        policy = np.zeros(u_discr)\n",
        "        # We extract the corresponding target policy, g(u_k|x_{k-1})\n",
        "        target_pol = self.g_u.target_policy(xkm1)\n",
        "        for u in range(u_discr):\n",
        "            # We get f(x_{k}|x_{k - 1}, u_k)\n",
        "            plant = f_x[xkm1][u]\n",
        "            # We get g(x_{k}|x_{k - 1}, u_k)\n",
        "            target_plant = g_x[xkm1][u]\n",
        "            # We sample plant for expectations\n",
        "            policy[u] = target_pol[u]*np.exp(-self.DKL(plant, target_plant) + np.dot(self.f.sample_gaussian(plant[0],plant[1], self.f.getXaxis()), gamma))\n",
        "        # We calculate the integral\n",
        "        S = np.sum(policy)\n",
        "        # We return the normalized result\n",
        "        return([elt/S for elt in policy]) \n",
        "\n",
        "    def closedLoop(self, tHor=0):\n",
        "\n",
        "        position = []\n",
        "        speed = []\n",
        "        x = 0\n",
        "\n",
        "        x_discr = self.f.getXdiscr()\n",
        "        u_discr = self.f.getUdiscr()\n",
        "\n",
        "        x_step = self.f.getXstep()\n",
        "        u_step = self.f.getUstep()\n",
        "\n",
        "        u_min = self.f.getUmin()\n",
        "\n",
        "        f_x = self.f.getPlant()\n",
        "\n",
        "        while(x < (x_discr*1200)/1500):\n",
        "            policy = self.runFPD(x, tHor) # We get the optimal policy\n",
        "            u = np.random.choice(range(u_discr), p=policy) # We choose a random index u from the policy according to the distribution of the policy\n",
        "            plant = f_x[x][u] # We get the conditional pmf of x_k: f(x_k|x_{k-1}, u_k)\n",
        "            # We get the new state from the plant\n",
        "            trueX = np.random.normal(plant[0],plant[1])\n",
        "            x = round(trueX/x_step)\n",
        "\n",
        "            x = max(x, 0)\n",
        "\n",
        "            # We compute the value of input from the input index\n",
        "            trueU = u_min + u_step*u\n",
        "            \n",
        "            position.append(trueX)\n",
        "            speed.append(trueU)\n",
        "\n",
        "            print(\"Speed: \" + str(trueU) + \" km/h\")\n",
        "            print(\"New position: \" + str(trueX) + \" m\")\n",
        "    \n",
        "        plt.figure(figsize=(8, 6), dpi=80)\n",
        "        plt.subplot(2,1,1)\n",
        "        plt.title(\"Simulation of the closed loop\")\n",
        "        plt.ylabel(r'Position $(m)$', fontsize=12)\n",
        "        plt.plot(position)\n",
        "        \n",
        "        plt.subplot(2,1,2)\n",
        "        plt.xlabel(r'Time $(s)$', fontsize=12)\n",
        "        plt.ylabel(r'Velocity $(km/h)$', fontsize=12)\n",
        "        plt.plot(speed)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbuKrt3fjJgn"
      },
      "source": [
        "$\\textbf{TargetPolicy}$\n",
        "\n",
        "This class provides an interface to obtain the probability distribution of the control input given the previous state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46qKB1-JjJgo"
      },
      "outputs": [],
      "source": [
        "class TargetPolicy:\n",
        "\n",
        "    def __init__(self, g, fmean, fstd):\n",
        "        self.g = g\n",
        "        self.g_u = [fmean(self.g.getXaxis()), fstd(self.g.getXaxis())]\n",
        "\n",
        "    def target_policy(self, indx):\n",
        "        return(self.g.sample_gaussian(self.g_u[0][indx], self.g_u[1][indx], self.g.getUaxis())) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0otg7mIPjJgo"
      },
      "source": [
        "$\\textbf{System parameters}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZRrjUK1jJgp"
      },
      "outputs": [],
      "source": [
        "#Bounds for u (velocity) and x (distance)\n",
        "v_min = 15\n",
        "v_max = 85\n",
        "\n",
        "d_min = 0\n",
        "d_max = 1500\n",
        "\n",
        "#Amount of bins (resolution) for u and x\n",
        "v_discr = 100\n",
        "d_discr = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpQwK4ZzjJgp"
      },
      "outputs": [],
      "source": [
        "#Parameters for f(x_k|x_{k-1},u_k)\n",
        "a_c = 0.982\n",
        "b_c = 0.2591\n",
        "sigma_c = 13.059\n",
        "\n",
        "#Parameters for g(x_k|x_{k-1},u_k)\n",
        "a_e = 0.9811\n",
        "b_e = 0.2723\n",
        "sigma_e = 8.811"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aSs0KK5jJgp"
      },
      "source": [
        "$\\textbf{Target policy}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dK7esbnijJgp"
      },
      "outputs": [],
      "source": [
        "# Target policy\n",
        "f1 = open('train_mean.json')\n",
        "f2 = open('train_std.json')\n",
        "\n",
        "means = json.load(f1)\n",
        "std = json.load(f2)\n",
        "\n",
        "# means[\"x\"] and means[\"y\"] are arrays of values used to approximate some function g(u_k|x_{k_1}). \n",
        "fmean = interpolate.interp1d(means['x'],means['y'], fill_value=\"extrapolate\")\n",
        "fstd = interpolate.interp1d(std['x'],std['y'], fill_value=\"extrapolate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6HnN8xLjJgq"
      },
      "outputs": [],
      "source": [
        "f = GaussianPlant(d_max, d_min, v_max, v_min, d_discr, v_discr, a_c, b_c, sigma_c, \"analytic\")\n",
        "g = GaussianPlant(d_max, d_min, v_max, v_min, d_discr, v_discr, a_e, b_e, sigma_e, \"analytic\")\n",
        "target_policy = TargetPolicy(g, fmean, fstd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ4kw_JzjJgq"
      },
      "source": [
        "$\\textbf{Closed loop simulation using analytic solver}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jn_BtUR0jJgq",
        "outputId": "6b5d12af-4eb1-4da6-821c-a818d50bedde"
      },
      "outputs": [],
      "source": [
        "solver = AnalyticalSolver(f, g, target_policy)\n",
        "solver.closedLoop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X82MbyOujJgr"
      },
      "source": [
        "$\\textbf{Closed loop simulation using numeric solver}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHmw35KPjJgr"
      },
      "outputs": [],
      "source": [
        "f = GaussianPlant(d_max, d_min, v_max, v_min, d_discr, v_discr, a_c, b_c, sigma_c, \"numeric\")\n",
        "g = GaussianPlant(d_max, d_min, v_max, v_min, d_discr, v_discr, a_e, b_e, sigma_e, \"numeric\")\n",
        "target_policy = TargetPolicy(g, fmean, fstd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7jOjm1FqjJgs",
        "outputId": "a44a1cfc-a771-4855-c086-c5985faeaf5e"
      },
      "outputs": [],
      "source": [
        "solver = NumericalSolver(f, g, target_policy)\n",
        "solver.closedLoop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G_aIF39jJgs"
      },
      "source": [
        "$\\textbf{Comparing then elapsed time as d\\_discr varies}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b6v7m1rjJgt",
        "outputId": "23b95ef4-2659-4186-a0c0-ca27a12bf735"
      },
      "outputs": [],
      "source": [
        "dict = {}\n",
        "\n",
        "for i in range(100, 900, 100):\n",
        "    v_discr = i\n",
        "    d_discr = i   \n",
        "    f = GaussianPlant(d_max, d_min, v_max, v_min, d_discr, v_discr, a_c, b_c, sigma_c, \"analytic\")\n",
        "    g = GaussianPlant(d_max, d_min, v_max, v_min, d_discr, v_discr, a_e, b_e, sigma_e, \"analytic\")\n",
        "    target_policy = TargetPolicy(g, fmean, fstd)\n",
        "\n",
        "    solver = AnalyticalSolver(f, g, target_policy)\n",
        "    t = time.time()\n",
        "    solver.closedLoop()\n",
        "    elapsed = time.time() - t\n",
        "    del f\n",
        "    del g\n",
        "    del target_policy\n",
        "    dict[i] = elapsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxV5vL7DjJgu"
      },
      "outputs": [],
      "source": [
        "discr = [d for d in dict.keys()]\n",
        "elapsed = [t for t in dict.values()]\n",
        "\n",
        "plt.title(r'Time elapsed for each $d\\_discr$')\n",
        "plt.xlabel(r'$d\\_discr$', fontsize=12)\n",
        "plt.ylabel(r'Time $(s)$', fontsize=12)\n",
        "plt.plot(discr, elapsed, 'bo')\n",
        "plt.show()\n",
        "plt.savefig(\"elapsed\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "WP5.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "581508afbd0fbea213fc77ca5200deccb432a5db675d975834481ab4759ab5b9"
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
